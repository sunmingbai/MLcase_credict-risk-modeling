# -*- coding: utf-8 -*-
"""MLcase.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MbQ9zmJPoI5sutFAUfs4Ugby6HkPJEym
"""





# pip install imbalanced-learn
# !pip install -U imbalanced-learn

# !pip install -U xgboost

import numpy  as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import warnings
warnings.simplefilter('ignore')

from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,plot_confusion_matrix,confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
# from category_encoders import target_encoder
from sklearn.pipeline import make_pipeline,Pipeline
from sklearn.ensemble import StackingClassifier
from xgboost import XGBClassifier
from imblearn.under_sampling import TomekLinks 
from imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTEENN
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from imblearn.pipeline import Pipeline 
from sklearn.base import BaseEstimator,TransformerMixin


# 修改路径名即可
newtrain=pd.read_csv('/content/drive/MyDrive/train_7w.csv').drop(columns=['REGION_RATING_CLIENT_W_CITY'])
newtest=pd.read_csv('/content/drive/MyDrive/test_2w.csv')

import xgboost
print("Scikit-Learn", xgboost.__version__)

!pip install category_encoders

from category_encoders import target_encoder

# 检查数据维度 需为61503*165 和24601*164
print('维度信息：',newtrain.shape,newtest.shape)

# 获取dummy后可保留的列名
app_train = pd.get_dummies(newtrain)
app_test = pd.get_dummies(newtest)

# train_target=app_train['TARGET']
# app_train = pd.get_dummies(newtrain)
# app_test = pd.get_dummies(newtest)
app_train,app_test=app_train.align(app_test,join='inner',axis=1)

# app_train = pd.get_dummies(newtrain)
# app_test = pd.get_dummies(newtest)
# app_train,app_test=app_train.align(app_test,join='inner',axis=1)
tarcol=[]
for col in app_train.columns:
    if col not in ['SK_ID_CURR','TARGET']:
      tarcol.append(col)


# 获取模型预测性能的函数
def getmetrics(y_true,y_pre):
    print('precison: ',precision_score(y_true,y_pre))
    print('recall: ',recall_score(y_true,y_pre))
    print('f1: ',f1_score(y_true,y_pre))
    print('accuracy: ',accuracy_score(y_true,y_pre))
    tn, fp, fn, tp = confusion_matrix(y_true, y_pre).ravel()
    cm=np.array([[tp,fp],[fn,tn]])
    sns.heatmap(cm,cmap='YlGnBu',annot=True,fmt='.20g')
    plt.xticks(ticks =[0.5,1.5] ,labels = np.array(['True_posi','True_nega']))
    plt.yticks(ticks =[0.5,1.5] ,labels = np.array(['Pre_posi','Pre_nega']))
#     plt.yticks(['预测正例','预测负例'])
    plt.show()
    

# get dummy for lr
class getdummy(BaseEstimator,TransformerMixin):
    def __init__(self,tarcol):
        self.tarcol=tarcol
        
    def fit(self,X,y=None):
        return self
    
    def transform(self,X,y=None):
        X_=pd.get_dummies(X)[self.tarcol]
        return X_

# 做pipeline 自动cv 输出结果的函数
def makepipe_getres(eastimators,set_param,cv_param,newtrain=newtrain,newtest=newtest,verbose=1,n_jobs=5,type_='Pipeline'):
    # verbose=1 show final metrics
    # =2 show best_params
    # =3 show cv_results_
    if type_=='Pipeline':
      initP=Pipeline(estimators)
    elif type_=='Stacking':
      initP=StackingClassifier(estimators=estimators, final_estimator=final_estimator)
    initP.set_params(**set_param)
    p_gs=GridSearchCV(initP,param_grid=cv_param,cv=5,verbose=3,n_jobs=n_jobs,scoring='f1',return_train_score=True)
    p_gs.fit(newtrain.drop(columns=['TARGET','SK_ID_CURR']),newtrain['TARGET'])
    if verbose>=3:
        print('cv_results:\n',p_gs.cv_results_)
        print('best_params:\n',p_gs.best_params_)
        
    elif verbose==2:
        print('best_params:\n',p_gs.best_params_)
    initP.set_params(**p_gs.best_params_)
    P=initP.fit(newtrain.drop(columns=['TARGET','SK_ID_CURR']),newtrain['TARGET'])
    pre=P.predict(newtest.drop(columns=['TARGET','SK_ID_CURR']))
    getmetrics(newtest['TARGET'],pre)
    
    return initP,P

SEED=42

from imblearn.ensemble import EasyEnsembleClassifier
from imblearn.ensemble import BalancedBaggingClassifier 
from imblearn.ensemble import BalancedRandomForestClassifier
from imblearn.ensemble import RUSBoostClassifier

# rf_p={'max_depth': 12, 'n_estimators': 5}
estimators=[('targetencode',target_encoder.TargetEncoder()),('rus',RUSBoostClassifier(n_estimators = 20,random_state=42,base_estimator = LogisticRegression()))]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)

pipe1=Pipeline(estimators)
pipe1.set_params(**init_param)

xgb_p={'max_depth': 5, 'n_estimators': 500}
estimators=[('targetencode',target_encoder.TargetEncoder()),('rus',RUSBoostClassifier(n_estimators = 20,random_state=42,base_estimator = XGBClassifier(**xgb_p)))]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)

pipe2=Pipeline(estimators)
pipe2.set_params(**init_param)

init_param={
}

estimators = [
        ('rf',pipe1),
        ('xgb', pipe2)
 ]
final_estimator=LogisticRegression()
initP=StackingClassifier(estimators=estimators, final_estimator=final_estimator)
initP.fit(newtrain.drop(columns=['TARGET','SK_ID_CURR']),newtrain['TARGET'])
pre_prob=initP.predict_proba(newtest.drop(columns=['TARGET','SK_ID_CURR']))
pre=initP.predict(newtest.drop(columns=['TARGET','SK_ID_CURR']))

getmetrics(newtest['TARGET'],pre)

from sklearn.metrics import roc_auc_score
roc_auc_score(newtest['TARGET'].values,pre_prob[:,1])

getmetrics(newtest['TARGET'],pre)

from sklearn.metrics import roc_auc_score
roc_auc_score(newtest['TARGET'].values,pre_prob[:,1])

"""## develop base model

### lr已经在个人端跑完
"""

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)
param_grid={
    'randomforest__n_estimators':[5,10,20,30,50],
    'randomforest__max_depth':[6,8,10,12]
}
initP_rf,P_rf=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

# rf
# import time
# time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
param_grid={
    'randomforest__max_depth':[6,7,8,9,10,11,12,13,14,15]
}

initP=Pipeline(estimators)
initP.set_params(**init_param)
p_gs=GridSearchCV(initP,param_grid=param_grid,cv=5,verbose=2,n_jobs=4,scoring='f1',return_train_score=True)
p_gs.fit(newtrain.drop(columns=['TARGET','SK_ID_CURR']),newtrain['TARGET'])


# time_end=time.time()
# print('totally cost',time_end-time_start)

p_gs.cv_results_

test_score=p_gs.cv_results_['mean_test_score']

train_score=p_gs.cv_results_['mean_train_score']

plt.plot( [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], train_score,label='Train Score')
plt.plot( [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], test_score,label='Test Score')
plt.legend()
plt.xlabel('max_depth')
plt.ylabel('metrics_f1')

from matplotlib.patches import Rectangle

ax = plt.gca()

# Create a Rectangle patch
rect = Rectangle((11,0),2,0.5,linestyle='--',linewidth=1,edgecolor='r',facecolor='none')

# Add the patch to the Axes
ax.add_patch(rect)

plt.title('Random Forest (with SMOTE) Over-fitting')

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
param_grid={
}
initP_rf_smote,P_rf_smote=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('tl',TomekLinks()),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
param_grid={
}
initP_rf_tl,P_rf_tl=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('smenn',SMOTEENN(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
param_grid={
}
initP_rf_se,P_rf_se=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

## xgb

import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__n_jobs=4)
param_grid={
    'xgb__n_estimators':[20,100,200,300,500],
    'xgb__max_depth':[5,9,11]
}
initP_xgb,P_xgb=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

## xgb

import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('tl',SMOTEENN()),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__n_jobs=4)
param_grid={
    'xgb__n_estimators':[500],
    'xgb__max_depth':[5]
}
initP_xgb_tl,P_xgb_tl=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

newtest['NAME_CONTRACT_TYPE']

'NAME_CONTRACT_TYPE' in newtrain.select_dtypes(include='object').columns

estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
P_rf_sm=Pipeline(estimators)
P_rf_sm.set_params(**init_param)

# estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('randomforest',RandomForestClassifier())]
# init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
# P_rf_sm=Pipeline(estimators)
# P_rf_sm.set_params(**init_param)

# estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('xgb',XGBClassifier())]
# init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__max_depth= 5, xgb__n_estimators= 500)
# P_xgb_sm=Pipeline(estimators)
# P_xgb_sm.set_params(**init_param)

# init_param={
#     'final_estimator__C': 0.5
# }

# estimators = [
#         ('rf', P_rf_sm),
#         ('xgb', P_xgb_sm)
#  ]
# final_estimator=LogisticRegression()

# param_grid={
# }

# import time
# time_start=time.time()

# initP_stack,P_stack=makepipe_getres(
#     estimators,
#     init_param,
#     param_grid,
#     type_='Stacking',
#     verbose=2
# )

# time_end=time.time()
# print('totally cost',time_end-time_start)

estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__max_depth= 5, xgb__n_estimators= 500)
P_xgb_sm=Pipeline(estimators)
P_xgb_sm.set_params(**init_param)

init_param={
    'final_estimator__C': 0.5
}

estimators = [
        ('rf', P_rf_sm),
        ('xgb', P_xgb_sm)
 ]
final_estimator=LogisticRegression()

param_grid={
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

estimators=[('targetencode',target_encoder.TargetEncoder()),('tl',TomekLinks()),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
P_rf_tl=Pipeline(estimators)
P_rf_tl.set_params(**init_param)

estimators=[('targetencode',target_encoder.TargetEncoder()),('tl',TomekLinks()),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__max_depth= 5, xgb__n_estimators= 500)
P_xgb_tl=Pipeline(estimators)
P_xgb_tl.set_params(**init_param)

init_param={
    'final_estimator__C': 0.5
}

estimators = [
        ('rf', P_rf_tl),
        ('xgb', P_xgb_tl)
 ]
final_estimator=LogisticRegression()

param_grid={
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

estimators=[('targetencode',target_encoder.TargetEncoder()),('se',SMOTEENN(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,randomforest__max_depth= 12, randomforest__n_estimators= 5)
P_rf_se=Pipeline(estimators)
P_rf_se.set_params(**init_param)

estimators=[('targetencode',target_encoder.TargetEncoder()),('se',SMOTEENN(random_state=SEED)),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__max_depth= 5, xgb__n_estimators= 500)
P_xgb_se=Pipeline(estimators)
P_xgb_se.set_params(**init_param)

init_param={
    'final_estimator__C': 0.5
}

estimators = [
        ('rf', P_rf_se),
        ('xgb', P_xgb_se)
 ]
final_estimator=LogisticRegression()

param_grid={
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

# 
## xgb

import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('sm',SMOTE(random_state=SEED)),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__n_jobs=4)
param_grid={
    'xgb__n_estimators':[500],
    'xgb__max_depth':[5]
}
initP_xgb_smote,P_xgb_smote=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2,
    n_jobs=4
)

time_end=time.time()
print('totally cost',time_end-time_start)

"""## smote stacking"""

init_param={}

estimators = [
        ('rf', P_rf_smote),
        ('xgb', P_xgb_smote)
 ]
final_estimator=LogisticRegression()

param_grid={
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

init_param={}

estimators = [
        ('rf', P_rf),
        ('xgb', P_xgb)
 ]
final_estimator=LogisticRegression()

param_grid={
    'final_estimator__C':[0.1,0.2,0.5]
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

#######################################################
# xgb
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('xgb',XGBClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns,xgb__tree_method='gpu_hist',xgb__n_jobs=5)
param_grid={
    'xgb__n_estimators':[500],
    'xgb__max_depth':[5],
    'xgb__scale_pos_weight':[1,7,10]
}
initP_xgb_weight,P_xgb_weight=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

# ##################################################
# # lr
# import time
# time_start=time.time()

# estimators=(('getdummy',getdummy(tarcol)),('lr',LogisticRegression()))
# init_param=dict()
# param_grid={
    # 'lr__C':[0.1,0.2,0.5],
    # 'lr__class_weight':[{0:1.0, 1:8.0},{0:1.0, 1:10.0}]
# }
# initP_lr,P_lr=makepipe_getres(
#     estimators,
#     init_param,
#     param_grid,
#     verbose=3
# )

# time_end=time.time()
# print('totally cost',time_end-time_start)

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)
param_grid={
    'randomforest__n_estimators':[5],
    'randomforest__max_depth':[12],
    'randomforest__class_weight':[{0:1.0, 1:1.0},{0:1.0, 1:7.0},{0:1.0, 1:10.0}]
}
initP_rf_weight,P_rf_weight=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=3
)

time_end=time.time()
print('totally cost',time_end-time_start)

init_param={}

estimators = [
        ('rf', P_rf_weight),
        ('xgb', P_xgb_weight)
 ]
final_estimator=LogisticRegression()

param_grid={
    'final_estimator__C':[0.1,0.2,0.5],
    'final_estimator__class_weight':[{0:1.0,1:1.0},{0:1.0,1:8.0}]
}

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

lr_param={
        'lr__C':[0.001,0.1,0.5],
        'lr__class_weight':[{0:1.0, 1:1.0},{0:1.0, 1:7.0},{0:1.0, 1:10.0}]
}

rf_estimators=[('targetencode',target_encoder.TargetEncoder(cols=newtrain.select_dtypes(include='object').columns)),('randomforest',RandomForestClassifier())]
xgb_estimators=[('targetencode',target_encoder.TargetEncoder(cols=newtrain.select_dtypes(include='object').columns)),('xgb',XGBClassifier(tree_method='gpu_hist',n_jobs=5))]

init_param={}

estimators = [
        ('rf', Pipeline(rf_estimators)),
        ('xgb', Pipeline(xgb_estimators))
 ]
final_estimator=LogisticRegression()

param_grid={
    'rf__randomforest__n_estimators':[30,50],
    'rf__randomforest__max_depth':[7,10],
    'rf__randomforest__class_weight':[{0:1.0,1:10.0}],
    'xgb__xgb__n_estimators':[70,100],
    'xgb__xgb__max_depth':[5,9],
    'xgb__xgb__scale_pos_weight':[7],
    'final_estimator__C':[0.1,0.2,0.5],
    'final_estimator__class_weight':[{0:1.0,1:1.0},{0:1.0,1:8.0}]
}

# clf=StackingClassifier(estimators=estimators, final_estimator=final_estimator)

import time
time_start=time.time()

initP_stack,P_stack=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    type_='Stacking',
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

# import time
# time_start=time.time()

# initP_stack,P_stack=makepipe_getres(
#     estimators,
#     init_param,
#     param_grid,
#     type_='Stacking',
#     verbose=2
# )

# time_end=time.time()
# print('totally cost',time_end-time_start)

######################################################
# rf
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('smote',SMOTE(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)
param_grid={
    'randomforest__n_estimators':[5,10,20,30,50],
    'randomforest__max_depth':[6,8,10,12],
    'randomforest__class_weight':[{0:1.0, 1:1.0},{0:1.0, 1:7.0},{0:1.0, 1:10.0}]
}
initP_rf_sm,P_rf_sm=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)

######################################################
# rf-enn
import time
time_start=time.time()

estimators=[('targetencode',target_encoder.TargetEncoder()),('smote_enn',SMOTEENN(random_state=SEED)),('randomforest',RandomForestClassifier())]
init_param=dict(targetencode__cols=newtrain.select_dtypes(include='object').columns)
param_grid={
    'randomforest__n_estimators':[5,10,20,30,50],
    'randomforest__max_depth':[6,8,10,12],
    'randomforest__class_weight':[{0:1.0, 1:1.0},{0:1.0, 1:7.0},{0:1.0, 1:10.0}]
}
initP_rf_enn,P_rf_enn=makepipe_getres(
    estimators,
    init_param,
    param_grid,
    verbose=2
)

time_end=time.time()
print('totally cost',time_end-time_start)





